{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD2Rk-ZDSMVx"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout,Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras import  datasets\n",
        "from matplotlib import pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "6V3cDL4G4WMF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt9t37WrhWy8"
      },
      "source": [
        "#Normalize image pixel values.\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "metadata": {
        "id": "AJCy3RlIuv4f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test=x_test.reshape(-1,784)\n",
        "# x_test_noisy=x_test_noisy.reshape(-1,784)\n",
        "# x_train_noisy=x_train_noisy.reshape(-1,784)\n",
        "# x_train=x_train.reshape(-1,784)"
      ],
      "metadata": {
        "id": "S3CgPeAvryrV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_HPGZBBjxkld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U2TPGTPrQvj",
        "outputId": "85ed86d8-0efb-4f23-a6a9-28695444a2a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORom-RTJZ-kp"
      },
      "source": [
        "# model=keras.Sequential() #Create a network sequence.\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# # model.add(Input(shape=(784,)))\n",
        "# model.add(Dense(128,activation = 'relu'))\n",
        "# model.add(Dense(64,activation = 'relu'))\n",
        "# model.add(Dense(32,activation = 'relu'))\n",
        "# model.add(Dense(64,activation = 'relu'))\n",
        "# model.add(Dense(128,activation = 'relu'))\n",
        "# model.add(Dense(784,activation = 'sigmoid'))\n",
        "\n",
        "# decoded.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skMSXinVhSPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7466aaf-f751-45cb-f9ce-070f50654b01"
      },
      "source": [
        "#model.compile(optimizer='Adam',loss=\"categorical_crossentropy\",metrics=['accuracy']) \n",
        "# model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy']) \n",
        "results= autoencoder.fit(x_train_noisy,x_train,epochs=10,batch_size=128,validation_data=(x_test_noisy, x_test))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 6s 8ms/step - loss: 0.2473 - accuracy: 0.7953 - val_loss: 0.1783 - val_accuracy: 0.7974\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1708 - accuracy: 0.7996 - val_loss: 0.1621 - val_accuracy: 0.7998\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1587 - accuracy: 0.8025 - val_loss: 0.1527 - val_accuracy: 0.8028\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1517 - accuracy: 0.8041 - val_loss: 0.1471 - val_accuracy: 0.8036\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1468 - accuracy: 0.8051 - val_loss: 0.1432 - val_accuracy: 0.8055\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1433 - accuracy: 0.8058 - val_loss: 0.1405 - val_accuracy: 0.8040\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1404 - accuracy: 0.8064 - val_loss: 0.1372 - val_accuracy: 0.8063\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.1378 - accuracy: 0.8069 - val_loss: 0.1351 - val_accuracy: 0.8061\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1359 - accuracy: 0.8073 - val_loss: 0.1334 - val_accuracy: 0.8070\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1342 - accuracy: 0.8076 - val_loss: 0.1323 - val_accuracy: 0.8071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQsuIhTzk3fE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a649c0eb-e661-4805-d2ec-aa2ecce817f9"
      },
      "source": [
        "score = autoencoder.evaluate(x_test_noisy, x_test)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.1323 - accuracy: 0.8071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x1=x_test.reshape(-1,28,28)\n",
        "# x2=x_test_noisy.reshape(-1,28,28)\n",
        "# x3=x_train.reshape(-1,28,28)\n",
        "# x4=x_train_noisy.reshape(-1,28,28)"
      ],
      "metadata": {
        "id": "nAc-72vhwO6C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=autoencoder.predict(x_test_noisy)\n",
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYFsXo2prE6n",
        "outputId": "e7e727cd-f804-4a61-b71e-acc682fb0ab0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1,2,1)\n",
        "plt.imshow(y_pred[0].reshape(28,28))\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(x_test[0].reshape(28,28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "oiOWzqKL6WzA",
        "outputId": "5f603a6e-8a49-4f84-d703-0b0684f1d3fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f72ed30b1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC4CAYAAAD61bdSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR5UlEQVR4nO3de5DV5X3H8c93L+zCLpGLgCuCeEEFbdTManXUltRLiYmDjtXIjIzTSYOTaEc6th2GTqrTXGqtl2i1mZKRQhy8RU211hid1UqcIAEcb4ACQYiYlUXlsqJ7//aPPXZWnue4l3N9Du/XjMM5333OOc9vz5evP37P8/wec3cBANJTVeoOAABGhgIOAImigANAoijgAJAoCjgAJIoCDgCJyqmAm9lcM3vbzLaa2eJ8dQooNXIbKbCRzgM3s2pJmyVdKGmnpLWS5rv7xmyvGWV1Xq+GEX0eMJgOHVCXd1qu70Nuo9xky+2aHN7zTElb3X2bJJnZQ5LmScqa5PVq0B/b+Tl8JJDdGm/J11uR2ygr2XI7l0soUyW9O+D5zkzsc8xsoZmtM7N13erM4eOAoiG3kYSCD2K6+1J3b3b35lrVFfrjgKIht1FquRTw9yRNG/D8qEwMSB25jSTkUsDXSpppZseY2ShJV0l6Mj/dAkqK3EYSRjyI6e49Zna9pF9Jqpa0zN035K1nQImQ20hFLrNQ5O5PS3o6T30Byga5jRSwEhMAEkUBB4BEUcABIFEUcABIFAUcABJFAQeARFHAASBRFHAASBQFHAASRQEHgERRwAEgURRwAEgUBRwAEkUBB4BEUcABIFEUcABIFAUcABJFAQeAROW0pZqZbZfULqlXUo+7N+ejU2XNLPf3cM/9PVBQh2RuIzk5FfCMr7r7B3l4H6DckNsoa1xCAYBE5VrAXdKzZrbezBbmo0NAmSC3UfZyvYRyrru/Z2aTJT1nZm+5+6qBDTLJv1CS6jUmx48DiobcRtnL6Qzc3d/L/Nkm6ReSzoy0Weruze7eXKu6XD4OKBpyGykY8Rm4mTVIqnL39szjiyT9U956VkxZZpZUTxgfxHpnHhVt21dbHb5tX3y2Se2O3UHMP/448qZDn63iXV3xfnV1Rxr3ZXkTZsdIFZbbqGi5XEKZIukX1l/8aiQ94O7P5KVXQGmR20jCiAu4u2+TdGoe+wKUBXIbqWAaIQAkigIOAInKx0rM8lQVDipKUvX4w4JYz0nTo23f/dtwYHDRSc9G246r/iSIteybHW37wvaZQaxjX1MQq6rvjb6+b39tEGt8J/5Vjt/cE8Rq2+PvW7fh3SDWu/vDaFv1xd8DpfPht88OYtMXbI22fattShDr6gzzSpKmPhjGx+yMDLpL6nt14xd1EXnGGTgAJIoCDgCJooADQKIo4ACQKAo4ACSqMmahRJbC10w7Mtq07c/CpfD75x6Itl1x6v1B7Pjajmjb7sgy9Kk1e6Jt/+RLb0fjB4vNbJGkA33hfTfe7ghnsUjSm+3h76HK4kvm1z4/K4gdtzKctSNJ/k44Y6WvI/67QXH8/d89EMQub4jnoI4bxhvPCUPbe+K5edfurw7jjUvrt21HR+MNt4c5X9OyvtDdGRHOwAEgURRwAEgUBRwAEkUBB4BEVcggZvj/Ia+NH5pH/pdVVRUf1NvcFS43frUjfuP+fb3hjiybD4Svl6Rt7RODWFdvuPS/tip+3+5d+8YGsSPH74u2vWjKpiDWPGZbtO3MS9qC2CMH5kTbznggHLDs2xEObKJ47l5yVRD7xy/Hz9HGbwpzfs+s+H3xR315bxC79ZTHo23vbFoTxP7nk8Yg9vUx8aX4w/Gph7e6WNPZEG07pz5yX/xIXyXp+G9eG8ROaBle34qFM3AASBQFHAASRQEHgERRwAEgURRwAEjUoLNQzGyZpG9IanP3UzKxCZIeljRD0nZJV7p7ljW7JbJ3fzQ8YeOXwqCFo+SS9IMtVwSxsTviH2fhvglqaItvejC6NVyGXN8VvoH1xGehHOPhDJDWyC0CJKnqOxuC2MSq+DLoU0bvDGI/O/nTaFtvDGfdpCbZ3M6i4dFwVkXDo0N/feRvRlb/dsScaPwH58wI3/fFcFOJW+ccP4xPi6v5NPz70fB6a7TtxFWPBbE/GhXfwGLM9ni8HA3lDHy5pLkHxRZLanH3mZJaMs+B1CwXuY2EDVrA3X2VpI8OCs+TtCLzeIWkS/PbLaDwyG2kbqQLeaa4+2f/VnlfUnzFiiQzWyhpoSTVK/1/dqPikdtIRs6DmO7ukuJLGft/vtTdm929uVbxVYxAOSK3Ue5Gega+y8ya3L3VzJokhWuwiymyQ3rf3vjS8urXwkG5SW/Gd7CfFAt2R5bkSlJ1+B7eExnZlKTeSH8jsWysJhxkmXBkfAhqT3e4tLjW4oOjM0eFX6P3xZdX277cl0KXqfLK7TLV8/6uaLzhsTAey+yGRz/Mc4/67fqrs6Pxk0eFpe62j06Mtp3xn+GtJrL8TS65kZ6BPynpmszjayQ9kZ/uACVHbiMZgxZwM3tQ0mpJJ5rZTjP7lqRbJF1oZlskXZB5DiSF3EbqBr2E4u7zs/zo/Dz3BSgqchupYyUmACSKAg4AiaqMDR0iss0A8WHM9lBkp/lyEDuGqs74cTVWdwaxSdXxWSh/6AnToX5zfbRt3569X9BDoPBqjp4WxO5Zck+0ba2Fs8R+ftcF0bYTW1fn1rEi4gwcABJFAQeARFHAASBRFHAASFTFDmJmVaYDk8NhkWX7bWfEb6b0l+PWB7GJVfG2z3RODmJTX8xyP/DOcHAUKKa3/mZqEDujLn7rhw1dYR5P2Bi/L35KOAMHgERRwAEgURRwAEgUBRwAEnXoDWKmxOIDMlWjw9WRnWe3R9tOqA43GujLskfBTasuC2KzNoX3Rpak3r70B4ORhs6vnxGNv/IXd0ai8Y01vnPDDUFs9G9+m0u3ygJn4ACQKAo4ACSKAg4AiaKAA0CiKOAAkKhBZ6GY2TJJ35DU5u6nZGI3S/q2pN2ZZkvc/elCdRKf59OPDGJ3f+WhaNtuD+8T/v3d8VH9WXftD2J97Vl2n/f4PcVTQm6n4fdfi59nNlo442T+OxdG24555rUgVgnzqIZyBr5c0txI/E53Py3zHwmOFC0XuY2EDVrA3X2VpI+K0BegqMhtpC6Xa+DXm9nrZrbMzMZna2RmC81snZmt6xZ3sEMSyG0kYaQF/CeSjpN0mqRWSbdna+juS9292d2ba7OskgLKCLmNZIxoKb277/rssZn9VNJTeesR/l/svt+S9Lurw5PC80fHzwDXdtYGsV/fcla07WHb3whi3tUV71wF3Fc9htwuraqxY4PYgvNeirbd39cRxNp+dGy0bV3n2tw6VqZGdAZuZk0Dnl4m6c38dAcoLXIbKRnKNMIHJc2RdLiZ7ZR0k6Q5Znaa+mfibJd0beG6CBQGuY3UDVrA3X1+JHxfAfoCFBW5jdSxEhMAEkUBB4BEsaFDmbDaUUGs46JTo21/Of9fI9H4TvPznw8v4c761aZo295PIrt0V+hsE5SnLTefHMSeOvzfo23nbbk8iNU9XZmzTbLhDBwAEkUBB4BEUcABIFEUcABIFIOYpRDZbd5mHxfEzv3hy9GXT68ZHcReznIvpVm37glivfvC+35LYsASRbPv6vjtHF7/5t1B7Hc93dG2H//LUUGsTq25dSwxnIEDQKIo4ACQKAo4ACSKAg4AiaKAA0CimIVSAlWNjUHsnX8Iv4oHJq6Jvr5P4SYNV7d8N9r2pN+HmzQw2wTFVDP1yCC26HsPR9vWWfj34KrXFkTbTvrlobVsPoYzcABIFAUcABJFAQeARFHAASBRQ9kTc5qkn0maov59Ape6+11mNkHSw5JmqH/vwCvdPVy3fQizmviv99PzTgpif33KM0EsNqAjST/+aHYQm3Vb/Fff25lljT3I7QKI5fypT+0MYlc0fhh9/cr2yUFsyvfi55l9w+xbJRrKGXiPpBvdfbaksyRdZ2azJS2W1OLuMyW1ZJ4DKSG3kbRBC7i7t7r7K5nH7ZI2SZoqaZ6kFZlmKyRdWqA+AgVBbiN1w5oHbmYzJJ0uaY2kKe7+2a2/3lf/P0Njr1koaaEk1WfZ9gsoNXIbKRryIKaZNUp6TNIid//c/Ujd3dV/DTHg7kvdvdndm2tVl1NngUIgt5GqIRVwM6tVf4KvdPfHM+FdZtaU+XmTpLbCdBEoHHIbKRvKLBSTdJ+kTe5+x4AfPSnpGkm3ZP58oiA9TEVkk4aqcYdFm+64PDyhu7gh3Cl+a0/863n43guC2ORt6+P9Ytl8VuR2AZx6YhD6/uT7h/zye390RRAb99rqnLpUyYZyDfwcSQskvWFmr2ZiS9Sf3I+Y2bck7ZB0ZUF6CBQOuY2kDVrA3f0lSeHpZb/z89sdoHjIbaSOlZgAkCgKOAAkivuB54nVhPfo/rT52Gjbe/40HNSZVB1+FY/uPTn6+qb/3hHEerq7BusikDfVs0+Ixhc+NLTx3tnLrovGZ9z/8oj7dCjiDBwAEkUBB4BEUcABIFEUcABIFAUcABLFLJQ8qZowLoh1LYrftP6i0QeCWGdkxft/vH5e9PUz92weVt+AfHvru+Oj8UvG7I/GD3bU/2aZNcWtH4aFM3AASBQFHAASRQEHgERRwAEgUQxiDlO2nea7T5gaxBZMfzbattaqg9j6yObxh704Oksnst1AD8i/jkvODGItl9yepTVbyxUTZ+AAkCgKOAAkigIOAImigANAogYt4GY2zcxeMLONZrbBzG7IxG82s/fM7NXMfxcXvrtA/pDbSN1QZqH0SLrR3V8xs7GS1pvZc5mf3enutxWue+Wnakx8lH33rPog1uHhJg+S1NYbLqV//uOvBLGGXb3R13tPzxd1EUNHbg/BH84JZ01Nrxn6bJOV7ZODWO3++FJ6FtIPz1A2NW6V1Jp53G5mmySFc+aAxJDbSN2wroGb2QxJp0takwldb2avm9kyM4ve3cbMFprZOjNb163IZGegDJDbSNGQC7iZNUp6TNIid98v6SeSjpN0mvrPYqIz+919qbs3u3tzrepy7zGQZ+Q2UjWkAm5mtepP8JXu/rgkufsud+919z5JP5UULtcCyhy5jZQNeg3czEzSfZI2ufsdA+JNmWuIknSZpDcL08UyMyo+MNkxMVze/syu+K7yY6s6gtjP3zk9iB2x/ePo6/u6GcTMB3I7//75w9lBbPWfzwhi3vpGEXpT+YYyC+UcSQskvWFmr2ZiSyTNN7PT1D9wvF3StQXoH1BI5DaSNpRZKC9Jit096en8dwcoHnIbqWMlJgAkigIOAImigANAotjQ4YvENk7Isoy9aXU4s+SD3dOjbe8ZdXQQO+I3e8OGW3bE++V98ThQAMcuXh3ELl4c3vohu/fz1xl8DmfgAJAoCjgAJIoCDgCJooADQKLMvXh34DWz3ZI+G5k7XNIHRfvw4uG4Sudod59Uig8ekNsp/J5GqlKPLYXjiuZ2UQv45z7YbJ27N5fkwwuI4zq0VfLvqVKPLeXj4hIKACSKAg4AiSplAV9aws8uJI7r0FbJv6dKPbZkj6tk18ABALnhEgoAJIoCDgCJKnoBN7O5Zva2mW01s8XF/vx8yuxY3mZmbw6ITTCz58xsS+bP6I7m5czMppnZC2a20cw2mNkNmXjyx1ZIlZLb5HU6x1bUAm5m1ZLulfQ1SbPVv3VVuIleOpZLmntQbLGkFnefKakl8zw1PZJudPfZks6SdF3me6qEYyuICsvt5SKvk1DsM/AzJW11923u3iXpIUnzityHvHH3VZI+Oig8T9KKzOMVki4tZp/ywd1b3f2VzON2SZskTVUFHFsBVUxuk9fpHFuxC/hUSe8OeL4zE6skUwbsaP6+pCml7EyuzGyGpNMlrVGFHVueVXpuV9R3Xyl5zSBmAXn/HM1k52maWaOkxyQtcvf9A3+W+rFh5FL/7ispr4tdwN+TNG3A86MysUqyy8yaJCnzZ1uJ+zMiZlar/iRf6e6PZ8IVcWwFUum5XRHffaXldbEL+FpJM83sGDMbJekqSU8WuQ+F9qSkazKPr5H0RAn7MiJmZpLuk7TJ3e8Y8KPkj62AKj23k//uKzGvi74S08wulvRjSdWSlrn7D4vagTwyswclzVH/7Sh3SbpJ0n9JekTSdPXfXvRKdz94QKismdm5kn4t6Q1Jn23AuUT91wuTPrZCqpTcJq/TOTaW0gNAohjEBIBEUcABIFEUcABIFAUcABJFAQeARFHAASBRFHAASNT/ATXVhxu/MhgLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}